# 1 Recitation Problems
[Recitation 20.pdf](https://www.yuque.com/attachments/yuque/0/2022/pdf/12393765/1662112344331-6e82274e-9c14-40cf-a4b8-68f6971a861a.pdf)
[Recitation 20_sol.pdf](https://www.yuque.com/attachments/yuque/0/2022/pdf/12393765/1662112344334-1071cabd-7ac2-4d1b-9701-7df056f0d3b5.pdf)
[Recitation 21.pdf](https://www.yuque.com/attachments/yuque/0/2022/pdf/12393765/1662112354778-fb8af434-5a98-46f0-84eb-80ff6096529e.pdf)
[Recitation 21_sol.pdf](https://www.yuque.com/attachments/yuque/0/2022/pdf/12393765/1662112354778-35b7daa1-cd9c-46ae-b8d4-618e35e371e5.pdf)


## P1 切比雪夫不等式估计**⭐**
> ![image.png](./__高阶知识点和练习_(1).assets/20231024_0906546987.png)

**(a)**![image.png](./__高阶知识点和练习_(1).assets/20231024_0906547985.png)
**(b)⭐⭐⭐**![image.png](./__高阶知识点和练习_(1).assets/20231024_0906551765.png)
所以$P(|Z_{50}-p|\leq 0.1)\geq 0.5$
**(c)**![image.png](./__高阶知识点和练习_(1).assets/20231024_0906595128.png)


## P2 依概率收敛1**⭐⭐⭐ **
> ![image.png](./__高阶知识点和练习_(1).assets/20231024_0907002189.png)

**(a)**![image.png](./__高阶知识点和练习_(1).assets/20231024_0907017698.png)
**(b) 切比雪夫不等式判断收敛性**![image.png](./__高阶知识点和练习_(1).assets/20231024_0907011009.png)
**(c) 依概率收敛**我们观察$Y_n$的`PMF`图像，发现:
$\lim_{n\to\infty}P(Y_n=0)=\lim_{n\to\infty}1-\frac{1}{n}=1$
但是我们需要使用[依概率收敛](https://www.yuque.com/alexman/kziggo/al5545#a2nk1)的定义。实际上:
对于任意$\epsilon>0$(假定$\epsilon\leq n$), 我们有$P(|Y_n|\geq\epsilon)=P(Y_n\geq \epsilon)=\frac{1}{n}$
而当$n\to \infty$时，$\lim_{n\to\infty}P(|Y_n|\geq\epsilon)=\lim_{n\to\infty}\frac{1}{n}=0$, 所以$Y_n$依概率收敛于$0$。
**(d) X依概率收敛，E[X] 不一定收敛**参考[依概率收敛](https://www.yuque.com/alexman/kziggo/al5545#a2nk1)中的算例$3$
![image.png](./__高阶知识点和练习_(1).assets/20231024_0907035883.png)



## P3 依概率收敛2**⭐⭐⭐⭐**
> ![image.png](./__高阶知识点和练习_(1).assets/20231024_0907058925.png)![image.png](./__高阶知识点和练习_(1).assets/20231024_0907054994.png)

**(a)**![image.png](./__高阶知识点和练习_(1).assets/20231024_0907063247.png)
**(b)**![image.png](./__高阶知识点和练习_(1).assets/20231024_0907075709.png)
**(c)**![image.png](./__高阶知识点和练习_(1).assets/20231024_0907075527.png)



# 2 Tutorial Problems
[Tutorial 10.pdf](https://www.yuque.com/attachments/yuque/0/2022/pdf/12393765/1662112344171-4306e0b7-fc52-4559-ba2a-42aef87ac509.pdf)
[Tutorial 10_sol.pdf](https://www.yuque.com/attachments/yuque/0/2022/pdf/12393765/1662112344370-a3bd264d-f92c-4bbe-a8b0-7e0d2c61b3ce.pdf)

## P1 切比雪夫不等式**⭐⭐⭐⭐⭐**
> ![image.png](./__高阶知识点和练习_(1).assets/20231024_0907087738.png)

**(a)**![image.png](./__高阶知识点和练习_(1).assets/20231024_0907108594.png)
**(b)**![image.png](./__高阶知识点和练习_(1).assets/20231024_0907102476.png)
**(c) 切比雪夫不等式**![image.png](./__高阶知识点和练习_(1).assets/20231024_0907116582.png)
**(d) 最大化方差⭐⭐⭐⭐⭐**![image.png](./__高阶知识点和练习_(1).assets/20231024_0907111355.png)

## Var[X] 的取值范围
> 对`P1`的$(d)$问，我们可以一般化下列结论:
> 对于一个取值范围是$[a,b]$的随机变量$X$，我们有如下结论:
> 1. $\argmin_c\{E[(X-c)^2]\}=E[X]$。
> 2. $E[(X-c)^2]$的最大值在$p_X(x)=\begin{cases}\frac{1}{2},X=a\\\frac{1}{2},X=b\end{cases}$时候取到。即$Var[X]\leq E[(X-\frac{a+b}{2})^2]$恒成立。


# 3 Assignment Problems
[Assignment 09.pdf](https://www.yuque.com/attachments/yuque/0/2022/pdf/12393765/1662112344312-4de9c305-1db2-4b97-926b-7bface6d88a0.pdf)
[Assignment 09_sol.pdf](https://www.yuque.com/attachments/yuque/0/2022/pdf/12393765/1662112344371-a7fe47e4-9c83-443f-9626-eb162b0c1514.pdf)
[Assignment 10.pdf](https://www.yuque.com/attachments/yuque/0/2022/pdf/12393765/1662192321016-2c278016-cc05-488c-89e0-cb21c0b375d9.pdf)
[Assignment 10_sol.pdf](https://www.yuque.com/attachments/yuque/0/2022/pdf/12393765/1662192321015-0d5764d0-a5b6-4643-a427-1a01f2463aed.pdf)


## P1 依概率收敛3（难）**⭐⭐⭐⭐⭐**
> ![image.png](./__高阶知识点和练习_(1).assets/20231024_0907139171.png)

**(a) 大数定律的应用 **![image.png](./__高阶知识点和练习_(1).assets/20231024_0907159244.png)
**(b) max依概率收敛⭐⭐⭐**![image.png](./__高阶知识点和练习_(1).assets/20231024_0907151424.png)
**(c) 较难⭐⭐⭐⭐⭐**$|V_n| \leq min\{|X_1|,|X_2|,\cdots,|X_n|\}$是因为$X_1,\cdots,X_n$都是在$[-1,1]$上的均匀分布，换句话说，$|X_1|,\cdots, |X_n|$都是在$[0,1]$上的均匀分布。我们知道，而绝对值小于等于$1$的数相乘，一定会比这些数字中绝对值最小的数字还要小，于是我们才有了上述结论，比较难想到。
同时本题还使用了积分的夹逼定理来确定其收敛性。
![image.png](./__高阶知识点和练习_(1).assets/20231024_0907162061.png)
假设$\epsilon>0$, 我们有:
$\lim_{i\to \infty}P(|min\{|X_1|,\cdots,|X_i|\}-0|>\epsilon)\newline=\lim_{i\to \infty}P(min\{|X_1|,\cdots,|X_i|\}>\epsilon)\newline=\lim_{i\to \infty}P(|X_1|>\epsilon)\cdots P(|X_i|>\epsilon)\newline=\lim_{i\to \infty}(1-\epsilon)^i=0$

## P2 Sharp Bound For Chebyshev **⭐⭐⭐⭐⭐**
> ![image.png](./__高阶知识点和练习_(1).assets/20231024_0907173724.png)
> **此类问题详见: **[https://en.wikipedia.org/wiki/Chebyshev%27s_inequality#Sharpness_of_bounds](https://en.wikipedia.org/wiki/Chebyshev%27s_inequality#Sharpness_of_bounds)

**Key**![image.png](./__高阶知识点和练习_(1).assets/20231024_0907181176.png)

## P3 One-Sided Chebyshev**⭐⭐⭐⭐⭐**
> ![image.png](./__高阶知识点和练习_(1).assets/20231024_0907197854.png)

**Key**因为$a>0,c\geq 0$, 所以$a+c>0$
我们有$P(X-\mu\geq a)=P(X-\mu+c\geq a+c)\newline\leq P((X-\mu+c)^2\geq (a+c)^2)$, 这个不等式成立是因为$X-\mu+c\sim N(c,\sigma^2)$, 所以$P(X-\mu+c\geq a+c)=P(X-\mu+c\leq -(a+c))$
所以$P((X-\mu+c)^2\geq (a+c^2))\newline=P(X-\mu+c\geq a+c)+P(X-\mu+c\leq -(a+c))\newline\geq P(X-\mu+c\geq a+c)$
然后$P((X-\mu+c)^2\geq (a+c)^2)\newline\leq \frac{E[(X-\mu+c)^2]}{(a+c)^2}\newline=\frac{E[(X-\mu)^2]+2c\cdot E(X-\mu)+E[c^2]}{(a+c)^2}$
由于$X-\mu\sim N(0,\sigma^2)$, 于是:
![image.png](./__高阶知识点和练习_(1).assets/20231024_0907208681.png)

## P4 A Financial Parable**⭐⭐⭐⭐**
> ![image.png](./__高阶知识点和练习_(1).assets/20231024_0907203177.png)

**(a) **![image.png](./__高阶知识点和练习_(1).assets/20231024_0907213479.png)
**(b) Diversification/CLT**![image.png](./__高阶知识点和练习_(1).assets/20231024_0907227024.png)
**(c) Covariance/CLT⭐⭐⭐⭐⭐**![image.png](./__高阶知识点和练习_(1).assets/20231024_0907236223.png)![image.png](./__高阶知识点和练习_(1).assets/20231024_0907246185.png)


## P5 随机变量的差的CLT**⭐⭐⭐**
> ![image.png](./__高阶知识点和练习_(1).assets/20231024_0907258760.png)

**Key**假设所有男性用$M_1,M_2,\cdots,M_{300}$表示，女性使用$F_1,F_2,\cdots,F_{196}$表示
根据题意，令投票的男性总数为$M=M_1+M_2+\cdots+M_{300}$, 女性为$F=F_1+F_2+\cdots+F_{196}$。则我们要估计的概率是$P(M-N\geq 0)$
因为$M_i,F_j$都是$Bernoulli, 且i,i,d$, 于是:
$E[M]=300\cdot 0.4=120$, $E[N]=196\cdot 0.5=98$
$Var[M]=300\cdot 0.4(1-0.4)=72$, $Var[N]=196\cdot 0.5\cdot 0.5=49$
于是$E[M-N]=E[M]-E[N]=22$, $Var[M-N]=Var[M]+Var[N]=121$
因为$300$和$196$足够大，所以$M-N$近似服从高斯分布$N\sim(22,121)$, 然后我们对其进行标准化，得到$P(M-N\geq 0)=P(\frac{M-N-22}{\sqrt{121}}\geq\frac{0-22}{\sqrt{121}})\newline\approx P(Z\geq -2)=0.9772$
我们也可以使用$\frac{1}{2}$`correction`提升估算的精度，因为$M-N$是一个整数，所以估计$P(M-N\geq 0)$可以写成$P(M-N\geq \frac{1}{2})$, 结果是:
![image.png](./__高阶知识点和练习_(1).assets/20231024_0907258634.png)


## P6 CLT/WLLN
> ![image.png](./__高阶知识点和练习_(1).assets/20231024_0907277673.png)

**(a) CLT**因为$S_n$是独立的伯努利随机变量之和，所以$E[S_n]=\frac{n}{2},Var[S_n]= \frac{1}{4}\cdot n$
于是我们使用中心极限定理: $P(\frac{n}{2}-10\leq S_n\leq \frac{n}{2}+10)\newline=P(\frac{-10}{\sqrt{\frac{1}{4}\cdot n}}\leq\frac{S_n-\frac{n}{2}}{\sqrt{\frac{1}{4}\cdot n}} \leq \frac{10}{\sqrt{\frac{1}{4}\cdot n}})\newline=P(\frac{-20}{\sqrt{n}}\leq Z_n \leq \frac{20}{\sqrt{n}})\approx\Phi(\frac{20}{\sqrt{n}})-\Phi(-\frac{20}{\sqrt{n}})$
当$n\to \infty$, $\Phi(\frac{20}{\sqrt{n}})-\Phi(-\frac{20}{\sqrt{n}}) \to 0$
**(b) WLLN**根据`WLLN`, 我们有$P(|\frac{S_n}{n}-\frac{1}{2}|\geq\frac{1}{10})=P(S_n\geq \frac{n}{2}+\frac{n}{10}\space or\space S_n\leq \frac{n}{2}-\frac{n}{10})\to0,n\to \infty$
而$P(S_n\geq \frac{n}{2}+\frac{n}{10}\space or\space S_n\leq \frac{n}{2}-\frac{n}{10})=1-P( \frac{n}{2}+\frac{n}{10}\leq S_n\leq \frac{n}{2}-\frac{n}{10})$。
所以$P( \frac{n}{2}+\frac{n}{10}\leq S_n\leq \frac{n}{2}-\frac{n}{10})\to 1,n\to \infty$
**(c) CLT**参考$(a)$问: $P(\frac{n}{2}-\frac{\sqrt{n}}{2}\leq S_n\leq \frac{n}{2}+\frac{\sqrt{n}}{2})=P(-1\leq \frac{S_n-\frac{n}{2}}{\frac{\sqrt{n}}{2}}\leq 1)$
![image.png](./__高阶知识点和练习_(1).assets/20231024_0907273027.png)


# 4 Extra Exercises
## P1 依概率收敛4
> ![image.png](./__高阶知识点和练习_(1).assets/20231024_0907284821.png)

**(a)**![image.png](./__高阶知识点和练习_(1).assets/20231024_0907288865.png)
![image.png](./__高阶知识点和练习_(1).assets/20231024_0907301994.png)
**(b)**![image.png](./__高阶知识点和练习_(1).assets/20231024_0907313144.png)


## P2 收敛于分布MGF视角
> ![image.png](./__高阶知识点和练习_(1).assets/20231024_0907323991.png)

**Key**![image.png](./__高阶知识点和练习_(1).assets/20231024_0907349380.png)
