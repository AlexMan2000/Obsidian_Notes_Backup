[L16 Slides.pdf](https://www.yuque.com/attachments/yuque/0/2022/pdf/12393765/1661916287575-0d2abfc6-104a-4bba-b1f9-91482487ac97.pdf)
# 0 前言
> ![image.png](离散马尔科夫链.assets/20231101_1702469706.png)
>  我们会探究一种模型，他将过去的影响总结成一个`State`, 且这个`State`根据给定的概率随时间变化。本章我们将这个模型限制在只能取有限数量的状态，且状态转移的概率和时间是独立的。我们想要探究`State Value`序列的概率性质。
> 本章描述的模型类型的应用范围非常广的。它包括几乎所有包含不确定性的动力系统，只要系统的**状态**被适当地定义。这样的系统出现在各种各样的领域，例如通信，自动控制，信号处理。制造、经济学和行为研究。



# 1 Discrete Time Markov Chain
## 1.0 前言
> 我们从离散伯努利分布出发来引出马尔科夫链的概念，假设我们有如下的伯努利序列:
> ![image.png](离散马尔科夫链.assets/20231101_1702461066.png)
> 则我们有如下的状态和其转移概率。
> ![image.png](离散马尔科夫链.assets/20231101_1702464658.png)
> 下面我们将正式介绍马尔科夫过程。




## 1.1 标准定义
> ![image.png](离散马尔科夫链.assets/20231101_1702478761.png)
> 随机变量$X_n$描述了马尔科夫状态，样本空间是离散的$S=\{1,\cdots m\}$($m$是正整数), 称为状态空间。马尔科夫链由状态转移概率$p_{ij}$组成，表示从状态$i$变成状态$j$的概率。



## 1.2 Markov Property**⭐⭐⭐⭐⭐**
:::info
马尔科夫链的一个重要性质/假设就是:
![image.png](离散马尔科夫链.assets/20231101_1702496695.png)
这个性质说的是，我知道了在$n$时刻我在状态$i$, 那么在$n$时刻之前我的状态序列对我在$n+1$时刻我的状态没有任何关系。也就是我不关心我是怎么在$n$时刻到达状态$i$的。
:::


## 1.3 n-step transition probability**⭐⭐⭐**
### 1.3.1 Definition
:::info
我们知道，在马尔科夫过程进行状态转移$i\to j$的过程中，有可能我们经历了一步，也可能经历了很多步。现在我们定义:
使用$n$步从状态$i$到状态$j$的概率是: $P_{ij}^{(n)}=P\{X_{m+n}=j|X_m=i\}$
:::


### 1.3.2 Recursion Formula
> 那么我们怎么计算这个`n-step transition probability`呢?
> 因为从状态$i$出发所能到达的状态$j$是可以列举出来的，所以$\sum_{j}P_{ij}^{(n)}=\sum_{j}P(X_n=j|X_0=i)=1$(因为$P$是一个合法的概率密度函数)。
> $n-step\space transition\space probability$探究的是从某个状态$i$开始, **在**$n$**次状态转移之后**的状态为$j$的概率。
> 我们可以从第$n$次状态转移开始反向考虑建立递归关系，如下图所示:
> ![image.png](离散马尔科夫链.assets/20231101_1702511781.png)
> 意思就是我经过了$n-1$步有可能转移到$1,2,...,m$这$m$种状态，用$k$表示具体转移到的某种状态，其概率是$P_{ik}^{(n-1)}$, 然后从第$n-1$步由状态$k$转移到第$n$步的状态$j$的概率是$p_{kj}$, 根据乘积法则相乘得到经过$n$步状态转移从$i\to k\to j$的转移概率， 然后将所有的$\to k\to j$的转移概率相加得到$r_{ij}(n)$, 就有了下面的递归公式:
> ![image.png](离散马尔科夫链.assets/20231101_1702527363.png)![image.png](离散马尔科夫链.assets/20231101_1702538895.png)
> 上面的推导是基于`Initial State`是状态$i$的情况，那么如果我们考虑所有的初始状态，则有:
> ![image.png](离散马尔科夫链.assets/20231101_1702558045.png)
> 根据全概率公式: $P(X_n=j)=\sum_{i=1}^m P(X_n=j|X_0=i)P(X_0=i)=\sum_{i=1}^m P(X_0=i)r_{ij}(n)$。




### 1.3.3 Chapman-Kolmogorov Equations
:::info
![image.png](离散马尔科夫链.assets/20231101_1702563495.png)
:::
**Proof**![image.png](离散马尔科夫链.assets/20231101_1702573179.png)


### 1.3.4 Probability of a Path⭐⭐⭐
> ![image.png](离散马尔科夫链.assets/20231101_1702589916.png)
> 总的来说我们只要沿着`Path`将沿途的所有状态转移概率相乘即可。
> ![image.png](离散马尔科夫链.assets/20231101_1703005577.png)
> $P(X_1=2,X_2=6,X_3=7|X_0=1)=p_{12}p_{26}p_{67}$
> $P(X_4=7|X_0=2)=p_{26}p_{67}p_{76}p_{67}+p_{26}p_{66}p_{66}p_{67}+p_{21}p_{12}p_{26}p_{67}$
> 但是如果$X_n$中的$n$很大的话，用这种方式会得到非常长的概率连乘，此时我们会转而使用$1.3$中的`Recursion Formula`来求解



## 1.4 Matrix Perspective**⭐⭐⭐⭐⭐**
### Markov Matrix
> 上面的推导略显繁琐，我们在矩阵的框架下进行阐述。
> ![image.png](离散马尔科夫链.assets/20231101_1703019599.png)
> 其中$P_{ij}=P(X_{m+1}=j|X_{m}=i)$, 也就是`One-step transition probability`。
> 令$P=\begin{bmatrix} P_{11}&P_{12}&\cdots &P_{1m}\\P_{21}&P_{22}&\cdots&P_{2m}\\\vdots&\vdots&\ddots&\vdots\\P_{m1}&P_{n2}&\cdots&P_{mm}\end{bmatrix}$, 则我们想证明$P^n=\begin{bmatrix} P_{11}^{(n)}&P_{12}^{(n)}&\cdots &P_{1m}^{(n)}\\P_{21}^{(n)}&P_{22}^{(n)}&\cdots&P_{2m}^{(n)}\\\vdots&\vdots&\ddots&\vdots\\P_{m1}^{(n)}&P_{m2}^{(n)}&\cdots&P_{mm}^{(n)}\end{bmatrix}$
> 我们使用数学归纳法: 
> 1. **Base Step: **$n=1$, 因为$P_{ij}^{(1)}=P_{ij}$by definition, 表示`1-step transition probability`
> 2. **Inductive Hypothesis: **假设$n=k\geq 1$, $P^k=\begin{bmatrix} P_{11}^{(k)}&P_{22}^{(k)}&\cdots &P_{1m}^{(k)}\\P_{21}^{(k)}&P_{22}^{(k)}&\cdots&P_{2m}^{(k)}\\\vdots&\vdots&\ddots&\vdots\\P_{m1}^{(k)}&P_{m2}^{(k)}&\cdots&P_{mm}^{(k)}\end{bmatrix}$成立。
> 3. **Inductive Step:** 对于$P^{k+1}$中的一项$P_{ij}^{(k+1)}$, 根据`Chapman-Kolmogorov Equation`可知: $P_{ij}^{(k+1)}=\sum_{k=1}^mP_{ik}^{(k)}P_{kj}$, 而$\sum_{k=1}^mP_{ik}^{(k)}P_{kj}$表示的正是$P^k$中的第$i$行和$P$中第$j$列向量的乘积。
> 
所以$\begin{aligned}P^{k+1}=P^kP&=\begin{bmatrix} P_{11}^{(k)}&P_{22}^{(k)}&\cdots &P_{1m}^{(k)}\\P_{21}^{(k)}&P_{22}^{(k)}&\cdots&P_{2m}^{(k)}\\\vdots&\vdots&\ddots&\vdots\\P_{m1}^{(k)}&P_{m2}^{(k)}&\cdots&P_{mm}^{(k)}\end{bmatrix}\begin{bmatrix} P_{11}&P_{22}&\cdots &P_{1m}\\P_{21}&P_{22}&\cdots&P_{2m}\\\vdots&\vdots&\ddots&\vdots\\P_{m1}&P_{n2}&\cdots&P_{mm}\end{bmatrix}\\&=\begin{bmatrix} P_{11}^{(k+1)}&P_{22}^{(k+1)}&\cdots &P_{1m}^{(k+1)}\\P_{21}^{(k+1)}&P_{22}^{(k+1)}&\cdots&P_{2m}^{(k+1)}\\\vdots&\vdots&\ddots&\vdots\\P_{m1}^{(k+1)}&P_{m2}^{(k+1)}&\cdots&P_{mm}^{(k+1)}\end{bmatrix}\end{aligned}$, 成立。
> 证毕。



### State Probability Distribution
> 假设我们有一个初始状态向量$\vec{\pi}_0=\begin{bmatrix} \pi_0(1)\\\pi_0(2)\\\vdots\\\pi_0(m)\end{bmatrix}\in \mathbb{R}^{m}$，状态空间是$\{1,2,\cdots, m\}$(也就是有$m$个状态)。
> 其中$\sum_{k=1}^m\pi_0(k)=1$, $\pi_0(k)$表示在`Time 0`的时候我们位于状态$k$的概率大小。
> 对于任意时刻$k$, $\vec{\pi}_k=\begin{bmatrix} \pi_k(1)\\\pi_k(2)\\\vdots\\\pi_k(m)\end{bmatrix}\in \mathbb{R}^{m}$, $\pi_k(i)=P(X_{k}=i)$, 表示在第$k$个时间步到达State k 的概率。
> 根据全概率公式我们有:
> $\begin{aligned}\pi_k(j)&=\sum_{i=1}^mP(X_k=j|X_{k-1}=i)P(X_{k-1}=i)\\&=\sum_{i=1}^mP(X_k=j|X_{k-1}=i)\pi_{k-1}(i)\\&=\sum_{i=1}^m\pi_{k-1}(i)P_{ij}\end{aligned}$
> 所以:
> $\vec{\pi}_{k+1}^{\top}=\pi_{k}^{\top}P$
> 所以我们有:
> $\pi_n^{\top}=\pi_0^{\top}P^n,n\geq 0$







## 1.5 Classification of States
### 1.5.1 Accessible States
> 状态$j$是`Accessible from`状态$i$如果$\exists n,P_{ij}^{(n)}>0$。
> 更详细的，there is a possible state sequence $i,i_1,\cdots, i_{n-1},j$, that starts at $i$and ends at $j$, in which the transitions $(i,i_1),(i_1.i_2),\cdots, (i_{n-2},i_{n-1}), (i_{n-1}, j)$all have positive probability. 


### 1.5.2 Recurrent/Transient States⭐⭐⭐⭐⭐
#### Definition
> 主要有两类: `Recurrent`和`Transient`
> ![image.png](离散马尔科夫链.assets/20231101_1703025549.png)
> 总的来说，`recurrent class`就是一个`class`进去了就出不去了。


#### Examples
> ![image.png](离散马尔科夫链.assets/20231101_1703047180.png)


#### Markov Decomposition
> ![image.png](离散马尔科夫链.assets/20231101_1703056367.png)
> 上图中，状态$5,6,7,8$都是`Recurrent`的。
> 状态$1,2,3,4$都是`Transient`的(因为$1\to 5$或者$2\to 6$总是有可能会发生，导致我们永远无法回到$1,2,3,4$)。
> 于是我们可以将这个马尔科夫过程中的状态分成两类:
> 蓝色的部分是`Recurrent Class`, 红色的部分是`Transient Class`, 一旦马尔科夫过程进入了`Recurrent Class`, 就卡在里面出不去了，和其他的`Class`之间就没有交流的通道了。
> ![image.png](离散马尔科夫链.assets/20231101_1703089729.png)
> 所以如果我们从一个`Recurrent State`开始马尔科夫过程，我们在$n\to \infty$步之后会收敛在`Recurrent Class`中。而如果我们从一个`Transient State`开始马尔科夫过程，我们不会收敛在`Transient Class`中。这也进一步验证了`Initial State`的选取确实会对马尔科夫的收敛性与否产生影响。
> 这种分类被称为`Markov Decomposition`:
> ![image.png](离散马尔科夫链.assets/20231101_1703094312.png)
> ![image.png](离散马尔科夫链.assets/20231101_1703102262.png)
> 我们再看一个例子:
> ![image.png](离散马尔科夫链.assets/20231101_1703126242.png)



### 1.5.3 Periodic Class⭐⭐
> `Periodicity`描述了一个`Reucurrent Class`内部的马尔科夫过程的状态转移方式。
> 对于一个`Recurrent Class`来说：
> ![image.png](离散马尔科夫链.assets/20231101_1703123819.png)
> $d=1\space or\space 2$**的情况:**
> ![image.png](离散马尔科夫链.assets/20231101_1703137132.png)
> $d=3$**的情况**
> ![image.png](离散马尔科夫链.assets/20231101_1703158153.png)
> 再看一个特殊的例子，对于下列的`Recurrent Class`:
> ![image.png](离散马尔科夫链.assets/20231101_1703163523.png)
> 红色的为$S_1$,白色的是$S_2$, $S_1$和$S_2$是`Disjoint`的， 所以这个`Recurrent Class`是周期性的。

**更严格的Periodicity的定义**![image.png](离散马尔科夫链.assets/20231101_1703176587.png)


# 2 State State Analysis
[L17 Slides.pdf](https://www.yuque.com/attachments/yuque/0/2022/pdf/12393765/1661923129939-79a4a155-e893-4388-84ae-617dc3d4d127.pdf)

## Steady-State Convergence Theorem
> [!thm]
> ![](离散马尔科夫链.assets/image-20231118182346859.png)![](离散马尔科夫链.assets/image-20231118182350646.png)![](离散马尔科夫链.assets/image-20231118182358973.png)
> 例如, 在$n\to\infty$时，`Markov Chain`已经收敛，此时$P(X_0=j)=\pi_j$, 则:
>  $\begin{align}P(X_2=j)&=\sum\limits_{t=1}^m\sum\limits_{k=1}^mP(X_2=j|X_1=k,X_0=t)P(X_1=k|X_0=t)P(X_0=t)\\&=\sum\limits_{t=1}^{m}\sum\limits_{k=1}^{m}p_{kj}\times p_{tk}\times\pi_t\\&=\sum\limits_{k=1}^{m}p_{kj} \sum\limits_{t=1}^{m}p_{tk}\times\pi_t\\&=\sum\limits_{k=1}^mp_{kj}\pi_k\\&=\pi_j\end{align}$ 
>  以此类推可以证明$P(X_n=j)=\pi_j$
>  所以$\lim_{n\to \infty}P(X_n=j|X_0=i)=\lim_{n\to \infty}P(X_n=j)=\pi_j$, 即$X_n$和$X_0$在$n\to \infty$时近似独立。



## Balance Equation
> [!summary]
> 对于一个`Single Aperiodic Class`的`Markov Process`来说，我们可以使用`Balance Equation`$\begin{cases}\pi=\pi P\\\sum\limits_{i=1}^n\pi_i=1\end{cases}$, 求出收敛概率, 其中$P$是`Markov Matrix`, 每一行的和为$1$。



## Frequency Prospective
> [!important]
> ![](离散马尔科夫链.assets/image-20231118174405725.png)![](离散马尔科夫链.assets/image-20231118174416654.png)



## Birth-Death Process
### Definition
> [!def]
> ![](离散马尔科夫链.assets/image-20231118174432513.png)

### Suumary
> [!summary]
> ![](离散马尔科夫链.assets/image-20231118180325768.png)
> 如果$\rho=1$, 则每个`State`的`Steady State Probability`是Equally likely的。
> 如果$\rho<1$且$m\to \infty$, 则：$p_{X_n}(i)=\rho^i(1-\rho)$, 所以$\mathbb{E}[X_n]=\sum\limits_{k=0}^{\infty}k\times (1-\rho)\times \rho^k=\frac{\rho}{1-\rho}$, 当$\rho\to 0$时，$\mathbb{E}[X_n]$是`Finite`的，但是当$\rho\to 1$时，图像就朝着`Infinity`进发了。



## Phone Call Process
> [!summary]
> ![](离散马尔科夫链.assets/image-20231118193413140.png)




# 3 Absorption State Analysis
## Absorption Probability
> [!def]
> ![](离散马尔科夫链.assets/image-20231118194932115.png)![](离散马尔科夫链.assets/image-20231118194941228.png)![](离散马尔科夫链.assets/image-20231118195013670.png)
> 更进一步，我们有$a_i=P(A|X_n=i),\forall n\in \mathbb{N}$
> 
> 

> [!example]
> ![](离散马尔科夫链.assets/image-20231118195428923.png)


## Expected Time to Absorption
> [!def]
> ![](离散马尔科夫链.assets/image-20231118195553121.png)![](离散马尔科夫链.assets/image-20231118195559342.png)

> [!example]
> ![](离散马尔科夫链.assets/image-20231118195609827.png)



## Mean First Passage and Recurrence Time
> [!def]
> ![](离散马尔科夫链.assets/image-20231118200308163.png)![](离散马尔科夫链.assets/image-20231118200321849.png)![](离散马尔科夫链.assets/image-20231118200331291.png)

> [!example]
> ![](离散马尔科夫链.assets/image-20231118200342991.png)![](离散马尔科夫链.assets/image-20231118200348929.png)



