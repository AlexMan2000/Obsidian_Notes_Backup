> Reading: 1.11 & Foundation of Data Science Section 12

[NotesOnNorms.pdf](https://www.yuque.com/attachments/yuque/0/2023/pdf/12393765/1675764020156-88c66559-7f51-432f-9e03-0ef6e523cfa3.pdf)
# 1 Norms of Vectors
## Definition
> **Formal Definition:**
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231202338.png)
> **换句话说就是, when **$p\geq 1$**:**
> 1. **Non negativity(Semi-positive definiteness):** $||\mathbf{x}||_p\geq 0~~and~~||\mathbf{x}||_p=0\iff \mathbf{x}=0$
> 2. **Scaling(Absolute Homogenity):** $||\alpha\mathbf{x}||_p=|\alpha|||\mathbf{x}||_p$
> 3. **Triangle Inequality:** $||x+y||_p\leq ||x||_p+||y||_p$
> 
所有的`**Vector Norm**`都必须满足上述的三个个性质，否则就不是合法的`**Vector Norm**`。


## Useful Inequalities
> 下面我们介绍一下在`Norm`证明中常用的不等式。


### Cauchy-Schwartz Inequality
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231206052.png)
> Only works for L2 Norm

**Proof**![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231208324.png)


### Jensen's Inequality
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231219926.png)

**Proof using variational method**![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231215966.png)

### Young's Inequality
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231215234.png)
> **注意:**$p,q,x,y\in \mathbb{R}^{+}$

**Proof(Convex Combination)****Quick Note on convex Combination:**
A convex combination is a linear combination of vectors in which the coefficients (or weights) used to combine the vectors are all nonnegative and sum to . In other words, a convex combination of vectors is a weighted average of those vectors, where the weights are all nonnegative and add up to .
For example, suppose we have two vectors  and  in a vector space . A convex combination of these vectors could be written as:

where alpha is a nonnegative coefficient (or weight) such that . This convex combination is a weighted average of  and , where the weight of  is alpha and the weight of  is .
**Now we use the property of convex combination to prove this inequality:**
![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231214330.png)


### Holder's Inequality
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231215905.png)
> **注意:** $p,q\in \mathbb{R}^{+}$, extends Cauchy-Schwartz Inequality to general cases. i.e. $l_p$norms

**Proof**![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231217797.png)
**Corollary(Apply Holder's Inequality)**![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231217139.png)

## Collections of Vector Norms
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231215970.png)
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231214662.png)
> **Exercise: **Prove that $||\mathbf{x}||_p$is a norm when $p\geq 1$

**Proof(Using Holder Inequality)**

1. **Positivity: **$||\mathbf{x}||_p=(|x_1|^p+\cdots+|x_p|^p)^{\frac{1}{p}}\geq 0$**, **and when $x_i=0,\forall i$, $||x||_p=0$
2. **Absolute Homogenity:** $\begin{align}||\alpha\mathbf{x}||_p&=(|\alpha x_1|^p+\cdots+|\alpha x_p|^p)^{\frac{1}{p}} \\&=(|\alpha|^p|x_1|^p+\cdots+|\alpha|^p|x_p|^p)^{\frac{1}{p}}\\&=|\alpha|(|x_1|^p+\cdots+|x_p|^p)^{\frac{1}{p}}\\&=|\alpha|||\mathbf{x}||_p\end{align}$
3. **Triangle Inequality:** $(\sum_{i=1}^n |x_i+y_i|^p)^{\frac{1}{p}}\leq (\sum_{i=1}^n |x_i|^p)^{\frac{1}{p}}(\sum_{i=1}^n|y_i|^p)^{\frac{1}{p}}$

根据`Triangle Inequality`, 首先我们有:
$|x_i+y_i|^p=|x_i+y_i|\cdot |x_i+y_i|^{p-1}\leq (|x_i|+|y_i|)|x_i+y_i|^{p-1}$
根据`Holder Inequality`, 我们有对于$\frac{1}{p}+\frac{1}{q}=1~~and~~p,q\in \mathbb{R}^{+}$:
$\begin{aligned} \sum_{i=1}^n |x_i|\cdot|x_i+y_i|^{p-1}&\leq (\sum_{i=1}^n|x_i|^p)^{\frac{1}{p}}(\sum_{i=1}^n (|x_i+y_i|^{p-1})^q)^{\frac{1}{q}}\\ \sum_{i=1}^n |y_i|\cdot|x_i+y_i|^{p-1}&\leq (\sum_{i=1}^n|y_i|^p)^{\frac{1}{p}}(\sum_{i=1}^n (|x_i+y_i|^{p-1})^q)^{\frac{1}{q}} \\\sum_{i=1}^n |x_i+y_i|^p&\leq  (\sum_{i=1}^n|y_i|^p)^{\frac{1}{p}}(\sum_{i=1}^n (|x_i+y_i|^{p-1})^q)^{\frac{1}{q}}+(\sum_{i=1}^n|x_i|^p)^{\frac{1}{p}}(\sum_{i=1}^n (|x_i+y_i|^{p-1})^q)^{\frac{1}{q}}\end{aligned}$
因为$\frac{1}{p}+\frac{1}{q}=1\implies (p-1)q=p$, 所以:
$\sum_{i=1}^n |x_i+y_i|^p\leq  (\sum_{i=1}^n|y_i|^p)^{\frac{1}{p}}(\sum_{i=1}^n |x_i+y_i|^p)^{\frac{1}{q}}+(\sum_{i=1}^n|x_i|^p)^{\frac{1}{p}}(\sum_{i=1}^n |x_i+y_i|^p)^{\frac{1}{q}}$
两边同时除以$(\sum_{i=1}^n |x_i+y_i|^p)^{\frac{1}{q}}$得到:
$\frac{\sum_{i=1}^n |x_i+y_i|^p}{(\sum_{i=1}^n |x_i+y_i|^p)^{\frac{1}{q}}}\leq  (\sum_{i=1}^n|y_i|^p)^{\frac{1}{p}}+(\sum_{i=1}^n|x_i|^p)^{\frac{1}{p}}$
因为$\frac{1}{p}+\frac{1}{q}=1\implies \frac{1}{p}=1-\frac{1}{q}$, 所以上述不等式变为:
$(\sum_{i=1}^n |x_i+y_i|^p)^{\frac{1}{p}}\leq  (\sum_{i=1}^n|y_i|^p)^{\frac{1}{p}}+(\sum_{i=1}^n|x_i|^p)^{\frac{1}{p}}$, 证毕。


### L-2 Norm
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231226510.png)



### L-1 Norm
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231228148.png)



### L-infty Norm
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231221403.png)



## Theorems&Questions on Norm
### Finite Equivalance
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231223725.png)


### Convexity
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231222384.png)


### Why P>=1?
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231228310.png)

**Proof**![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231226342.png)
**Graphical Explanations**![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231225420.png)![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231228887.png)

### Lemma
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231221696.png)



## Textbook Notes
### Lp Norms
> 在所有的$L^p$Norm 中，只有当$1\leq p\leq \infty$才满足`Norm`的两个要求，`Rescaling`和`Triangle Inequality`
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231234674.png)
> $l_0$norm = zero norm. $||v||_0=number~~of~~non-zero~~entry$
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231237829.png)(except for the origin)
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231233278.png)![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231236789.png)
> 一个很有价值的发现是: 对于$l^p$Norm来说，当$p$从$0$到$\infty$变化的过程中，假设$\mathbf{v}\in \mathbb{R}^2$我们可以发现在二维平面上满足 $||\mathbf{v}||=1$的点组成的集合的图像会逐步扩张，成顶点为$(1,1),(1,-1),(-1,1),(-1,-1)$的正方形。



### Constrained Optimization
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231234397.png)![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231237212.png)![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231236149.png)


### Inner Product Under L2 Norm
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231237549.png)![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231234449.png)


### Inner Product Under S Norm
> $l^1$和$l^{\infty}$没有和$l^2$一样的`Dot Product`的写法。
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231239176.png)![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231232905.png)![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231236539.png)



## 


# 2 Norm of Matrices
## Definition
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231245031.png)

**Proof of the new matrix norm**![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231245934.png)


## Collections of Matrix Norms
### Frobenius Norm
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231248033.png)
> **Why?**
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231244574.png)![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231249427.png)



### Nuclear Norm
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231244808.png)



### Induced Matrix Norms
#### Operator Norm
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231246327.png)
> 我们看到，这里$||A||$是通过`Vector Norm`来定义的，所以称为`Induced Matrix Norms`

 


#### P-Norm
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231243098.png)



### Generalized Induced Norm
#### Definitions
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231243473.png)![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231245101.png)



#### Theorems
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231244512.png)

**Proof**![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231247825.png)




### Show whether it's norm
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231259893.png)

**Frobenius**


### Examples
**Example**![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231252204.png)

## Properties of Matrix Norms
### Submultiplicativity
#### Definition&Theorems
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231257101.png)![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231253822.png)
> ** In other words, induced matrix norms are submultiplicative.  **

**Proof**![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231251298.png)

#### Operator 2-norm
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231254013.png)



#### Frobenius Norm
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231255468.png)![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231257436.png)

**Proof**![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231258469.png)


### Inequality
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231256870.png)



### Orthogonal Invariant
#### Theorems
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231259914.png)![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231254642.png)![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231263762.png)![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231261879.png)



#### Exercises
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231268074.png)



### Miscellanous Properties
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231268974.png)![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231266693.png)


## Textbook Notes
### Largest Growth Factor
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231267743.png)



### Important Matrix Norms
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231267363.png)
> 其中$||A||_2$尤为重要，因为他和我们学过的奇异值分解结合了起来，如下:
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231263249.png)

**Important Properties**![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231263530.png)


# 3 Exercises
## P1 L1,L2, L-infty
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231267339.png)

**Proof**Let $max(|v_1|,\cdots, |v_n|)=|v_m|$
$\begin{align}||v||_2^2&=|v_1|^2+|v_2|^2+\cdots+|v_n|^2\\&=|v_1||v_1|+\cdots +|v_n||v_n|\\&\leq |v_1||v_m|+\cdots |v_n||v_m|\\&=\sum_{i=1}^n |v_i|\times max(|v_i|)\\&=||v||_1\times ||v||_{\infty}\end{align}$


## P2 Cauchy-Schwarz Inequality
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231267759.png)
> 注意`Cauchy-Schwarz Inequality`只对`L2 Norm`成立。

**Proof**![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231275929.png)


## P3 Application of P1&P2⭐⭐⭐⭐
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231271364.png)

**Proof**假设$max(|v_1|,\cdots, |v_n|)=|v_m|$
首先对于$||v||_2\leq \sqrt{n}||v||_{\infty}$, 我们有:
$\begin{align}||v||_2&=\sqrt{|v_1|^2+\cdots |v_n|^2}\\&\leq\sqrt{|v_m|^2\times n} \\&=\sqrt{n}|v_m|\\&=\sqrt{n}||v||_{\infty}\end{align}$
对于$||v||_1\leq \sqrt{n}||v||_2$, 我们使用`P2`的思想, $w$的选取非常巧妙:
![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231274313.png)


## P4 Dual Norms
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231278932.png)
> `Holder's Inequality`对所有的`Vector Norm`都成立。

**Proof**![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231279394.png)

## P5 Inner Product
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231271046.png)

**Solution**![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231271781.png)

## P6 Triangle Inequality
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231274402.png)

**Proof**![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231278106.png)


## P7 Lemmas
> ![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231279024.png)

**Proof**![image.png](./1.11_Norms_of_Vectors_and_Matrices.assets/20230302_1231273713.png)
